{
  "@context": [
    "https://www.w3.org/ns/credentials/v2"
  ],
  "id": "urn:uuid:1b2984e0-7687-4463-9e9e-6bcb2589a2f1",
  "type": "VerifiableCredential",
  "name": null,
  "description": null,
  "issuer": "did:volt:bed919ab-6081-40e7-9677-88d1cd37a0c0",
  "validFrom": null,
  "validUntil": null,
  "credentialStatus": null,
  "credentialSchema": {
    "id": "https://json-schema.org/draft/2020-12/schema",
    "type": "JsonSchema"
  },
  "credentialSubject": {
    "$id": "https://github.com/nqminds/Trusted-AI-BOM/blob/main/packages/schemas/src/taibom-schemas/20-data-pack.v1.0.1.schema.yaml",
    "$schema": "https://json-schema.org/draft/2019-09/schema",
    "context": "## Introduction\n\nThe **TAIBOM Datapack Schema** is a JSON schema designed to describe and standardise collections of datasets within the Trusted AI BOM (TAIBOM) ecosystem. This schema ensures that groups of datasets, whether used for raw data, training, or testing, are organised and verified for integrity.\n\n### Description\nThis schema captures essential metadata for datapacks, including:\n- **Name**: A unique identifier for the datapack.\n- **Datasets**: A collection of dataset objects, each containing:\n  - A unique identifier (`id`) for traceability.\n  - A cryptographic hash (`hash`) to ensure data integrity.\n\n## Use Case\n\nThe **TAIBOM Datapack Schema** is primarily used within the TAIBOM framework to:\n1. **Organise Dataset Collections**: Provide a standardised format for grouping datasets used in AI workflows.\n2. **Enable Traceability**: Ensure that each dataset in the collection is uniquely identified and linked to its source.\n3. **Streamline Dataset Verification**: Facilitate verification and management of multiple datasets within a single datapack.\n\nBy adopting this schema, organisations can effectively manage and document groups of datasets, ensuring integrity and ease of use in AI system development and deployment.\n\n---\n",
    "description": "A datapack schema that describes a collection of datasets used for raw data, training data, and testing data.  Each collection has a unique identifier and a cryptographic hash for verifying data integrity.\n",
    "examples": [
      {
        "datasets": [
          {
            "hash": "3b74b7f0b762998774a97b2c4c648a0f8c51f04d6c74f2e7698f4d8b9",
            "id": "urn:uuid:data-vc-1234"
          },
          {
            "hash": "23d9f32cb1628925d3f048cf3eb8f1ea4f7e61f3f3426a0c33b5df5b5a",
            "id": "urn:uuid:data-vc-4567"
          }
        ],
        "name": "Raw collection"
      }
    ],
    "properties": {
      "datasets": {
        "description": "A list of dataset objects, each containing an ID and a cryptographic hash.\n",
        "items": {
          "properties": {
            "hash": {
              "description": "The cryptographic hash (e.g., SHA-256) of the dataset for data integrity.",
              "type": "string"
            },
            "id": {
              "description": "The unique identifier of the dataset, such as a VC ID or a DID.",
              "format": "uri",
              "type": "string"
            }
          },
          "required": [
            "id",
            "hash"
          ],
          "type": "object"
        },
        "minItems": 1,
        "type": "array",
        "uniqueItems": true
      },
      "name": {
        "description": "The name of the datapack.",
        "type": "string"
      }
    },
    "required": [
      "name",
      "datasets"
    ],
    "title": "TAIBOM Datapack",
    "type": "object"
  },
  "proof": {
    "type": "DataIntegrityProof",
    "created": "2024-12-05T11:49:59.078130589Z",
    "cryptosuite": "eddsa-rdfc-2022",
    "proofPurpose": "assertionMethod",
    "proofValue": "rJ4owVDgekARilZP0yP9quhfEcBBWAPAj9nOZdDSlJI6I6ADqLjfKpBD77piVh1CFgiRgJnugPuofesaQWbEBQ=="
  }
}