$id: https://github.com/nqminds/Trusted-AI-BOM/blob/main/packages/schemas/src/taibom-schemas/60-attestation.v1.0.0.schema.yaml
$schema: https://json-schema.org/draft/2020-12/schema
title: Attestations
description: |
  This schema defines a generic attestation to any component of an AI system
type: object
properties:
  component:
    type: string
    description: Component ID of a VC claim
  attestation: 
    type: object
    description: Attestation made about the component
required:
  - component
  - attestation
examples:
  - id: urn:uuid:223e4567-e89b-12d3-a456-426614174003
    component: urn:uuid:222e3337-e89b-12d3-a456-426614174004
    attestation:
      type: Bias Assessment
      claimant: AI Ethics Auditor Team
      organization: Ethical AI Oversight Board
      date: 2024-11-28
      description: >
        The AI component's decision-making process was audited, and evidence of potential
        gender bias was identified.
      findings:
        - biasType: gender
          evidence: >
            The system exhibited a 15% lower selection rate for female candidates
            during evaluation tests.
        - recommendations:
            - Perform rebalancing of training data to address gender imbalance.
            - Implement post-hoc fairness adjustments.
      evidence:
        - type: report
          url: https://example.com/audit-reports/223e4567
          checksum: sha256:123456abcdef123456abcdef123456abcdef123456abcdef123456abcdef123456
  - id: urn:uuid:333e4567-e89b-12d3-a456-426614174005
    component: urn:uuid:333e4447-e89b-12d3-a456-426614174006
    attestation:
      type: Performance Evaluation
      claimant: Jane Smith
      role: QA Tester
      organization: AI Performance Testing Labs
      date: 2024-11-28
      description: >
        The component was tested for throughput and latency under load, achieving 
        performance targets outlined in the specifications.
      metrics:
        - metricName: throughput
          value: 5000
          unit: transactions/second
          description: The component maintained throughput above 5000 transactions/second under standard conditions.
        - metricName: latency
          value: 20
          unit: milliseconds
          description: Average latency was 20ms, meeting SLA requirements.
      evidence:
        - type: log
          url: https://example.com/performance-test-results/333e4567
          checksum: sha256:abcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdefabcdef
        - type: video
          url: https://example.com/videos/performance-demo.mp4

context: |
  ## Introduction

  The **Attestation Schema** is a JSON schema designed to define and standardise attestations made about components within an AI system. These attestations provide essential information about various claims, ranging from performance metrics to ethical reviews, supporting traceability and accountability within the Trusted AI BOM (TAIBOM) framework.

  ### Description
  This schema captures attestations with the following details:
  - **Component**: The component being attested to, identified by a unique ID.
  - **Attestation**: The claim made about the component, including its type, claimant, and supporting evidence.

  ### Types of Attestations
  Attestations can take any form, such as:
  - **SBOM Claims**: Verifying a Software Bill of Materials (SBOM) by a third party.
  - **CVE Claims**: AI agents asserting vulnerabilities.
  - **Bias Claims**: Ethical audits identifying biases in AI components.
  - **Best Practice Claims**: Statements affirming adherence to industry best practices.
  - **Performance Claims**: Testers documenting performance metrics.

  ## Use Case

  The **Attestation Schema** is used to:
  1. **Document Claims**: Provide a formal structure for recording attestations related to AI system components.
  2. **Support Accountability**: Ensure claims about AI components are transparent and traceable.
  3. **Enable Audits and Compliance**: Facilitate ethical and performance audits by linking components with attestations and evidence.

  By employing this schema, organisations can ensure robust tracking and verification of claims made about AI system components, enhancing trust and accountability within AI ecosystems.
